{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdO/z1A7Yp4nfj1iA0nIiG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/richiam16/chat_researcher/blob/main/Templates/template_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatPI- Test case and Use in Colab"
      ],
      "metadata": {
        "id": "AycRDgdSXtKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the dependencies and enviroment to use ChatPI"
      ],
      "metadata": {
        "id": "r8flaOc_X1sY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bHs6Mg7XpBW"
      },
      "outputs": [],
      "source": [
        "# Install mamba to simplify dependencies in the enviroment\n",
        "\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "# This will restart the kernel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up Git variables\n",
        "\n",
        "!git config --global user.email “user@email.com”\n",
        "!git config --global user.name “github_name”\n",
        "\n",
        "#Download replacing git_token with your personal token: !git clone https://git_token@github.com/richiam16/chat_researcher.git\n",
        "# If you do not have a git_token: get one with these instructions:https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\n",
        "\n",
        "!git clone https://git_token@github.com/richiam16/chat_researcher.git\n"
      ],
      "metadata": {
        "id": "bQGB_KXIYATx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the enviroment (This can take a couple of minutes)\n",
        "!pip install pubmed2pdf==0.0.3\n",
        "!mamba install biopython langchain openai pypdf chromadb tiktoken"
      ],
      "metadata": {
        "id": "6f3oZa-dZsRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use ChatPI in colab"
      ],
      "metadata": {
        "id": "5oXxrE2raIjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the .py files to use the chat and the os\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"chat_researcher/\")\n",
        "\n",
        "#Import pi_chat from the chat_implementation.py file\n",
        "\n",
        "from chat_implementation import pi_chat\n",
        "import os\n",
        "\n",
        "\n",
        "# Import the values for the function and for using the APIs (Bio and openAI)\n",
        "# Open AI key (https://community.openai.com/t/how-do-i-get-my-api-key/29343)\n",
        "os.environ['OPENAI_API_KEY'] = \"\"\n",
        "name = \"\" # Name of the PI to chat with their papers\n",
        "email = \"\" # Mandatory to use PubMed Api\n",
        "number_papers =  # (Rule of thumb: n + 10, where n is the number of papers you want to retrieve)\n",
        "model_name = \"gpt-3.5-turbo\" # Name of GPT model as implemented in OpenAI API https://platform.openai.com/docs/models\n",
        "path_pubmed = \"chat_researcher/Data/PDFs\" # Folder to download the papers (Not mandatory, default: \"chat_researcher/Data/PDFs\")\n",
        "path_directory =  \"chat_researcher/Data/Vectorstore\" # Folder to save the Chroma database (Not mandatory, \"chat_researcher/Data/Vectorstore\")\n",
        "\n",
        "rag = pi_chat(name=name, email=email, number_papers=number_papers, model_name=model_name)"
      ],
      "metadata": {
        "id": "QhBJS8P9Zv85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask a question with rag.invoke(\"question\")\n",
        "rag.invoke(\"question\")"
      ],
      "metadata": {
        "id": "CeGdPISzZziw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}